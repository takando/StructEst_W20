{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Structural Estimation HW4\n",
    "\n",
    "### Takuya Ando"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import packages and load the data\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import numpy.random as rnd\n",
    "import numpy.linalg as lin\n",
    "import scipy.stats as sts\n",
    "import scipy.integrate as intgr\n",
    "import scipy.optimize as opt\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from matplotlib import cm\n",
    "cmap1 = matplotlib.cm.get_cmap('summer')\n",
    "# This next command is specifically for Jupyter Notebook\n",
    "%matplotlib inline\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(a)Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>c_t</th>\n",
       "      <th>k_t</th>\n",
       "      <th>w_t</th>\n",
       "      <th>r_t</th>\n",
       "      <th>y_t</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.128323e+07</td>\n",
       "      <td>8.040697e+06</td>\n",
       "      <td>1.120211e+07</td>\n",
       "      <td>1.008852</td>\n",
       "      <td>1.931398e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.215464e+07</td>\n",
       "      <td>8.030754e+06</td>\n",
       "      <td>1.206726e+07</td>\n",
       "      <td>1.088112</td>\n",
       "      <td>2.080561e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.097303e+07</td>\n",
       "      <td>8.650974e+06</td>\n",
       "      <td>1.089414e+07</td>\n",
       "      <td>0.911904</td>\n",
       "      <td>1.878300e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9.711635e+06</td>\n",
       "      <td>7.809971e+06</td>\n",
       "      <td>9.641815e+06</td>\n",
       "      <td>0.893986</td>\n",
       "      <td>1.662382e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9.245673e+06</td>\n",
       "      <td>6.912184e+06</td>\n",
       "      <td>9.179203e+06</td>\n",
       "      <td>0.961637</td>\n",
       "      <td>1.582621e+07</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            c_t           k_t           w_t       r_t           y_t\n",
       "0  1.128323e+07  8.040697e+06  1.120211e+07  1.008852  1.931398e+07\n",
       "1  1.215464e+07  8.030754e+06  1.206726e+07  1.088112  2.080561e+07\n",
       "2  1.097303e+07  8.650974e+06  1.089414e+07  0.911904  1.878300e+07\n",
       "3  9.711635e+06  7.809971e+06  9.641815e+06  0.893986  1.662382e+07\n",
       "4  9.245673e+06  6.912184e+06  9.179203e+06  0.961637  1.582621e+07"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "macro = pd.read_csv(\"data/NewMacroSeries.txt\", header=None)\n",
    "macro.columns = [\"c_t\", \"k_t\", \"w_t\", \"r_t\", \"y_t\"]\n",
    "macro.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we define function that draws N x S values from a normal distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def norm_draws(unif_vals, mu, sigma):\n",
    "    '''\n",
    "    This fundtion draws T x S values from a normal distribution\n",
    "    based on uniform distribution\n",
    "    '''\n",
    "    norm_draws = sts.norm.ppf(unif_vals, loc=0, scale=sigma)\n",
    "    \n",
    "    return norm_draws"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, we define another function which generate simulation values for z, k, w, r, c and y."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sim_draw(unif_vals, k, alpha, beta, mu, sigma, p, T, S):\n",
    "    '''\n",
    "    This function draws simulation values for z, k, w, r, c and y.\n",
    "    '''\n",
    "    draws = norm_draws(unif_vals, mu, sigma)\n",
    "    \n",
    "    # z simulation draw\n",
    "    z_sim = np.zeros((T,S))\n",
    "\n",
    "    z_sim[0,:] = p * mu + (1-p) * mu + draws[0, :]\n",
    "\n",
    "    for i in range(1, len(z_sim)):\n",
    "        z_sim[i,:] = p * z_sim[i-1,:] + (1-p) * mu + draws[i,:]\n",
    "    \n",
    "    # k simulation draw\n",
    "    k_sim = np.zeros((T+1, S))\n",
    "\n",
    "    k_sim[0] = np.mean(k)\n",
    "\n",
    "    for i in range(1, T+1):\n",
    "        k_sim[i,:]=alpha*beta*np.exp(z_sim[i-1,:])*((k_sim[i-1,:])**alpha)\n",
    "    \n",
    "    # w, r simulation draw\n",
    "    w_sim = np.zeros((T, S))\n",
    "\n",
    "    r_sim = np.zeros((T, S))\n",
    "\n",
    "    for i in range(T):\n",
    "        w_sim[i, :] = (1-alpha)*np.exp(z_sim[i,:])*((k_sim[i,:])**alpha)\n",
    "        r_sim[i, :] = alpha*np.exp(z_sim[i,:])*((k_sim[i,:])**(alpha-1))\n",
    "    \n",
    "    # c simulation draw\n",
    "    c_sim = np.zeros((T, S))\n",
    "\n",
    "    for i in range(T):\n",
    "        c_sim[i,:] = w_sim[i, :] + np.multiply(r_sim[i, :], k_sim[i, :]) - k_sim[i+1, :]\n",
    "    \n",
    "    # y simulation draw\n",
    "    y_sim = np.zeros((T, S))\n",
    "   \n",
    "    for i in range(T):\n",
    "        y_sim[i, :]=np.exp(z_sim[i,:])*((k_sim[i,:])**alpha)\n",
    "    \n",
    "    \n",
    "    k_sim = k_sim[0:100, :]\n",
    "    \n",
    "    return z_sim, k_sim, w_sim, r_sim, c_sim, y_sim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, we degine moment function both for data and model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def moments(k, w, r, c, y, data=True):\n",
    "    '''\n",
    "    This function compute moments for observed data \n",
    "    and simulation values(moments vector of length S)\n",
    "    '''\n",
    "    if data:\n",
    "        mean_c = np.mean(c)\n",
    "        mean_k = np.mean(k)\n",
    "        mean_c_y = np.mean(np.divide(c, y))\n",
    "        var_y = np.var(y)\n",
    "        c_t = c[1:100]\n",
    "        c_t_1 = c[0:99]\n",
    "        corr_c = np.corrcoef(c_t, c_t_1)[1, 0]\n",
    "        corr_ck = np.corrcoef(c, k)[1, 0]\n",
    "    else:\n",
    "        mean_c = np.mean(c, axis=0)\n",
    "        mean_k = np.mean(k, axis=0)\n",
    "        mean_c_y = np.mean(np.divide(c, y), axis=0)\n",
    "        var_y = np.var(y, axis=0)\n",
    "        c_t = c[1:100, :]\n",
    "        c_t_1 = c[0:99, :]\n",
    "        corr_c = np.zeros(1000)\n",
    "        for i in range(1000):\n",
    "            corr_c[i] = np.corrcoef(c_t[:,i], c_t_1[:,i])[1, 0]\n",
    "        corr_ck = np.zeros(1000)\n",
    "        for i in range(1000):\n",
    "            corr_ck[i] = np.corrcoef(c[:,i], k[:,i])[1, 0]\n",
    "    \n",
    "    return mean_c, mean_k, mean_c_y, var_y, corr_c, corr_ck"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also, we define error vector and criterion functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def err_vec(data_vals, unif_vals, alpha, beta, mu, sigma, p, T, S, simple):\n",
    "    '''\n",
    "    --------------------------------------------------------------------\n",
    "    This function computes the vector of moment errors (in percent\n",
    "    deviation from the data moment vector) for SMM.\n",
    "    --------------------------------------------------------------------\n",
    "    '''\n",
    "    k, w, r, c, y = data_vals\n",
    "    \n",
    "    z_sim, k_sim, w_sim, r_sim, c_sim, y_sim = \\\n",
    "    sim_draw(unif_vals, k, alpha, beta, mu, sigma, p, T, S)\n",
    "    \n",
    "    mom_data1, mom_data2, mom_data3, mom_data4,\\\n",
    "    mom_data5 ,mom_data6, = moments(k, w, r, c, y, data=True)\n",
    "    \n",
    "    moms_data = np.array([mom_data1, mom_data2, mom_data3, mom_data4, mom_data5, mom_data6])\n",
    "    \n",
    "    mom_sim1, mom_sim2, mom_sim3, mom_sim4,\\\n",
    "    mom_sim5 ,mom_sim6, = moments(k_sim, w_sim, r_sim, c_sim, y_sim, data=False)\n",
    "    \n",
    "    moms_model = np.array([np.mean(mom_sim1), np.mean(mom_sim2), np.mean(mom_sim3),\\\n",
    "                           np.mean(mom_sim4), np.mean(mom_sim5), np.mean(mom_sim6)])\n",
    "    \n",
    "    if simple:\n",
    "        err_vec = moms_model - moms_data\n",
    "    else:\n",
    "        err_vec = (moms_model - moms_data) / moms_data\n",
    "    \n",
    "    return err_vec\n",
    "\n",
    "\n",
    "def criterion(params, *args):\n",
    "    '''\n",
    "    --------------------------------------------------------------------\n",
    "    This function computes the SMM weighted sum of squared moment errors\n",
    "    criterion function value given parameter values and an estimate of\n",
    "    the weighting matrix.\n",
    "    --------------------------------------------------------------------\n",
    "    '''\n",
    "    alpha, mu, sigma, p = params\n",
    "    beta=0.99\n",
    "    datavals, unif_vals, T, S, W_hat = args\n",
    "    err = err_vec(datavals, unif_vals, alpha, beta, mu, sigma, p, T, S, simple=False)\n",
    "    crit_val = err.T @ W_hat @ err\n",
    "    \n",
    "    return crit_val"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we perform SMM estimation. The estimated parametes are alpha_SMM1= 0.42105186489272567, mu_SMM1= 9.935073825212754, sig_SMM1= 0.08846794502048456 and p_SMM1= 0.9204782651500025. The minimized criterion function value is 4.485252339611445e-06."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alpha_SMM1= 0.42105186489272567  mu_SMM1= 9.935073825212754  sig_SMM1= 0.08846794502048456  p_SMM1= 0.9204782651500025\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "      fun: 4.485252339611445e-06\n",
       " hess_inv: <4x4 LbfgsInvHessProduct with dtype=float64>\n",
       "      jac: array([-2.95966572e-04, -1.31317897e-05, -1.74179734e-05, -1.49612368e-05])\n",
       "  message: b'CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH'\n",
       "     nfev: 295\n",
       "      nit: 42\n",
       "   status: 0\n",
       "  success: True\n",
       "        x: array([0.42105186, 9.93507383, 0.08846795, 0.92047827])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extract observed data\n",
    "k = macro.k_t\n",
    "w = macro.w_t\n",
    "r = macro.r_t\n",
    "c = macro.c_t\n",
    "y = macro.y_t\n",
    "\n",
    "# Set T and S\n",
    "T = 100\n",
    "S = 1000\n",
    "\n",
    "# Set initial parameters\n",
    "alpha_init = 0.5\n",
    "\n",
    "z = np.log(r/(alpha_init*(k**(alpha_init-1))))\n",
    "\n",
    "mu_init = np.mean(z)\n",
    "\n",
    "sigma_init = np.sqrt(np.var(z))\n",
    "\n",
    "p_init = 0.01\n",
    "\n",
    "params_init1 = np.array([alpha_init, mu_init, sigma_init, p_init])\n",
    "\n",
    "datavals = (k, w, r, c, y)\n",
    "\n",
    "# Generate uniform distribution\n",
    "np.random.seed(1)\n",
    "unif_vals = sts.uniform.rvs(0, 1, size=(T, S)) \n",
    "\n",
    "W_hat1 = np.eye(6)\n",
    "smm_args1 = (datavals, unif_vals, T, S, W_hat1)\n",
    "results1 = opt.minimize(criterion, params_init1, args=(smm_args1),\n",
    "                          method='L-BFGS-B',\n",
    "                          bounds=((1e-10, 1-1e-10), (1e-10, None), (1e-10, None),(-1+1e-10, 1-1e-10)))\n",
    "alpha_SMM1, mu_SMM1, sig_SMM1, p_SMM1 = results1.x\n",
    "print('alpha_SMM1=', alpha_SMM1, ' mu_SMM1=', mu_SMM1, ' sig_SMM1=', sig_SMM1, ' p_SMM1=', p_SMM1)\n",
    "results1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also, vector of moment difference at the optimmum is as below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 7.54546152e-04, -7.65937633e-04, -1.78251668e-03, -3.49684770e-07,\n",
       "        2.74872686e-04, -2.76280946e-04])"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "err_vec(datavals, unif_vals, alpha_SMM1, 0.99, mu_SMM1, sig_SMM1, p_SMM1, T, S, False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, we will examine the standard error of each estimation. Here we define Jacobian matrix function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Jac_err(data_vals, unif_vals, alpha, mu, sigma, p, simple=False):\n",
    "    '''\n",
    "    This function computes the Jacobian matrix of partial derivatives of the R x 1 moment\n",
    "    error vector e(x|theta) with respect to the K parameters theta_i in the K x 1 parameter vector\n",
    "    theta. The resulting matrix is R x K Jacobian.\n",
    "    '''\n",
    "    Jac_err = np.zeros((6, 4))\n",
    "    h_alpha = 1e-4 * alpha\n",
    "    h_mu = 1e-4 * mu\n",
    "    h_sig = 1e-4 * sigma\n",
    "    h_p = 1e-4 * p\n",
    "    Jac_err[:, 0] = \\\n",
    "        ((err_vec(data_vals, unif_vals, alpha + h_alpha, 0.99, mu, sigma, p,T,S, simple) -\n",
    "          err_vec(data_vals, unif_vals, alpha - h_alpha, 0.99, mu, sigma, p,T,S, simple)) / (2 * h_alpha)).flatten()\n",
    "    \n",
    "    Jac_err[:, 1] = \\\n",
    "        ((err_vec(data_vals, unif_vals, alpha, 0.99, mu + h_mu, sigma, p,T,S, simple) -\n",
    "          err_vec(data_vals, unif_vals, alpha, 0.99, mu - h_mu, sigma, p,T,S, simple)) / (2 * h_mu)).flatten()\n",
    "    \n",
    "    Jac_err[:, 2] = \\\n",
    "        ((err_vec(data_vals, unif_vals, alpha, 0.99, mu, sigma + h_sig, p,T,S, simple) -\n",
    "          err_vec(data_vals, unif_vals, alpha, 0.99, mu, sigma - h_sig, p,T,S, simple)) / (2 * h_sig)).flatten()\n",
    "    \n",
    "    Jac_err[:, 3] = \\\n",
    "        ((err_vec(data_vals, unif_vals, alpha, 0.99, mu, sigma, p + h_p,T,S, simple) -\n",
    "          err_vec(data_vals, unif_vals, alpha, 0.99, mu, sigma, p - h_p,T,S, simple)) / (2 * h_p)).flatten()\n",
    "    \n",
    "    \n",
    "    return Jac_err"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using Jacobian matrix, we calculate variance covariance matrix for estimated parameters. Below are Jacobian matrix, variance covariance matrix and standard errors for estimated parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 2.70583090e+01  1.71639333e+00  1.41467162e+00  7.27242023e-01]\n",
      " [ 3.07732830e+01  1.69651151e+00  1.39682340e+00  7.18879220e-01]\n",
      " [-1.69462513e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00]\n",
      " [ 6.12934420e+01  3.45799097e+00  2.71843717e+01  1.18921732e+01]\n",
      " [ 1.28677827e-01  8.44926888e-05 -8.82548804e-02  4.25360501e-01]\n",
      " [ 2.03204601e-01  4.14372768e-03 -8.60920976e-02  4.31000793e-01]]\n",
      "[[ 9.02516162e-05 -1.51843610e-03  1.67231785e-06 -2.74587936e-05]\n",
      " [-1.51843610e-03  2.57747430e-02  1.58600670e-05  2.92261561e-04]\n",
      " [ 1.67231785e-06  1.58600670e-05  4.28096020e-04 -9.88645142e-04]\n",
      " [-2.74587936e-05  2.92261561e-04 -9.88645142e-04  2.31715017e-03]]\n",
      "Std. err. alpha_hat= 0.009500085064042714\n",
      "Std. err. mu_hat= 0.1605451431783314\n",
      "Std. err. sig_hat= 0.020690481376158337\n",
      "Std. err. p_hat= 0.048136786063251585\n"
     ]
    }
   ],
   "source": [
    "d_err1 = Jac_err(datavals, unif_vals, alpha_SMM1, mu_SMM1, sig_SMM1, p_SMM1, False)\n",
    "print(d_err1)\n",
    "SigHat1 = (1 / S) * lin.inv(d_err1.T @ W_hat1 @ d_err1)\n",
    "print(SigHat1)\n",
    "print('Std. err. alpha_hat=', np.sqrt(SigHat1[0, 0]))\n",
    "print('Std. err. mu_hat=', np.sqrt(SigHat1[1, 1]))\n",
    "print('Std. err. sig_hat=', np.sqrt(SigHat1[2, 2]))\n",
    "print('Std. err. p_hat=', np.sqrt(SigHat1[3, 3]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(b)First, we construct the error matrix function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_Err_mat(datavals, unif_vals, alpha, beta, mu, sigma, p, simple=False):\n",
    "    '''\n",
    "    --------------------------------------------------------------------\n",
    "    This function computes the R x S matrix of errors from each\n",
    "    simulated moment for each moment error. In this function, we have\n",
    "    hard coded R = 6.\n",
    "    --------------------------------------------------------------------\n",
    "    '''\n",
    "    R = 6\n",
    "    S = 1000\n",
    "    T = 100\n",
    "    Err_mat = np.zeros((R, S))\n",
    "    k, w, r, c, y = datavals\n",
    "    \n",
    "    z_sim, k_sim, w_sim, r_sim, c_sim, y_sim = \\\n",
    "    sim_draw(unif_vals, k, alpha, beta, mu, sigma, p, T, S)\n",
    "    \n",
    "    mom_data1, mom_data2, mom_data3, mom_data4,\\\n",
    "    mom_data5 ,mom_data6, = moments(k, w, r, c, y, data=True)\n",
    "    \n",
    "    mom_sim1, mom_sim2, mom_sim3, mom_sim4,\\\n",
    "    mom_sim5 ,mom_sim6, = moments(k_sim, w_sim, r_sim, c_sim, y_sim, data=False)\n",
    "    \n",
    "    if simple:\n",
    "        Err_mat[0, :] = mom_sim1 - mom_data1\n",
    "        Err_mat[1, :] = mom_sim2 - mom_data2\n",
    "        Err_mat[2, :] = mom_sim3 - mom_data3\n",
    "        Err_mat[3, :] = mom_sim4 - mom_data4\n",
    "        Err_mat[4, :] = mom_sim5 - mom_data5\n",
    "        Err_mat[5, :] = mom_sim6 - mom_data6\n",
    "        \n",
    "        \n",
    "    else:\n",
    "        Err_mat[0, :] = (mom_sim1 - mom_data1) / mom_data1\n",
    "        Err_mat[1, :] = (mom_sim2 - mom_data2) / mom_data2\n",
    "        Err_mat[2, :] = (mom_sim3 - mom_data3) / mom_data3\n",
    "        Err_mat[3, :] = (mom_sim4 - mom_data4) / mom_data4\n",
    "        Err_mat[4, :] = (mom_sim5 - mom_data5) / mom_data5\n",
    "        Err_mat[5, :] = (mom_sim6 - mom_data6) / mom_data6\n",
    "    \n",
    "    return Err_mat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, we will construct optimal weighting matrix using the parameters from (a). the optimal weighting matrix is as follows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 2.96467480e-02  2.94244849e-02 -1.34499110e-06  7.76814009e-02\n",
      "   7.51482709e-04  7.58574521e-04]\n",
      " [ 2.94244849e-02  2.92199398e-02  1.36529661e-06  7.71700387e-02\n",
      "   7.44525977e-04  7.52563748e-04]\n",
      " [-1.34499110e-06  1.36529661e-06  3.17736571e-06  6.23318936e-10\n",
      "  -4.89965147e-07  4.92475394e-07]\n",
      " [ 7.76814009e-02  7.71700387e-02  6.23318936e-10  5.46273686e-01\n",
      "   1.27167783e-02  1.27711668e-02]\n",
      " [ 7.51482709e-04  7.44525977e-04 -4.89965147e-07  1.27167783e-02\n",
      "   8.29124518e-04  8.26520517e-04]\n",
      " [ 7.58574521e-04  7.52563748e-04  4.92475394e-07  1.27711668e-02\n",
      "   8.26520517e-04  8.25558551e-04]]\n",
      "(6, 6)\n"
     ]
    }
   ],
   "source": [
    "Err_mat = get_Err_mat(datavals, unif_vals, alpha_SMM1, 0.99, mu_SMM1, sig_SMM1, p_SMM1, False)\n",
    "VCV = (1 / S) * (Err_mat @ Err_mat.T)\n",
    "print(VCV)\n",
    "# Because VCV4 is poorly conditioned we use the pseudo-inverse to invert it, which\n",
    "# uses the SVD\n",
    "W_hat2 = lin.pinv(VCV)\n",
    "print(W_hat2.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we perform SMM using optimal weighting matrix. The estimated parameters and minimized criterion function values are as below. The estimated parameters do not change much and minimized criterion function value becomes larger."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alpha_SMM2= 0.4207519656565238  mu_SMM2= 9.934591487172444  sig_SMM2= 0.0873344718660021  p_SMM2= 0.9227031553066365\n",
      "      fun: 0.7158887680866852\n",
      " hess_inv: <4x4 LbfgsInvHessProduct with dtype=float64>\n",
      "      jac: array([ 6.59252319e-02, -8.10462808e-06, -2.25851560e-03, -6.88504809e-04])\n",
      "  message: b'CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH'\n",
      "     nfev: 195\n",
      "      nit: 33\n",
      "   status: 0\n",
      "  success: True\n",
      "        x: array([0.42075197, 9.93459149, 0.08733447, 0.92270316])\n"
     ]
    }
   ],
   "source": [
    "params_init2 = np.array([alpha_SMM1, mu_SMM1, sig_SMM1, p_SMM1])\n",
    "\n",
    "smm_args2 = (datavals, unif_vals, T, S, W_hat2)\n",
    "results2 = opt.minimize(criterion, params_init2, args=(smm_args2),\n",
    "                          method='L-BFGS-B',\n",
    "                          bounds=((1e-10, 1-1e-10), (1e-10, None), (1e-10, None),(-1+1e-10, 1-1e-10)))\n",
    "alpha_SMM2, mu_SMM2, sig_SMM2, p_SMM2 = results2.x\n",
    "print('alpha_SMM2=', alpha_SMM2, ' mu_SMM2=', mu_SMM2, ' sig_SMM2=', sig_SMM2, ' p_SMM2=', p_SMM2)\n",
    "print(results2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The difference vector values at the optimum below also becomes larger."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.00811926, -0.01073198, -0.0012743 , -0.0240484 ,  0.00128095,\n",
       "        0.00071323])"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "err_vec(datavals, unif_vals, alpha_SMM2, 0.99, mu_SMM2, sig_SMM2, p_SMM2, T, S, False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, what about standard error for each estimated parameter? Below we show standard errors for each paramter using optimized weighting matrix. We can see that standard errors are much smaller than parameters using identity weighting matrix. Thus, these etimated parameters are much efficient. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 2.67875848e+01  1.70027484e+00  1.42028810e+00  7.38929363e-01]\n",
      " [ 3.04336685e+01  1.67853231e+00  1.40067115e+00  7.29536758e-01]\n",
      " [-1.69462513e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00]\n",
      " [ 5.97553588e+01  3.37263099e+00  2.68851319e+01  1.18325819e+01]\n",
      " [ 1.29355719e-01  2.30200838e-04 -8.73739082e-02  4.24393475e-01]\n",
      " [ 2.18349910e-01  5.08610602e-03 -8.45958595e-02  4.30321310e-01]]\n",
      "[[ 3.16561009e-10  4.01849212e-10  1.21475466e-09 -2.39653822e-09]\n",
      " [ 4.01849212e-10  8.37616235e-06  1.13566614e-07 -9.37697395e-07]\n",
      " [ 1.21475466e-09  1.13566614e-07  4.11771239e-07 -6.17819778e-07]\n",
      " [-2.39653822e-09 -9.37697395e-07 -6.17819778e-07  3.86425086e-06]]\n",
      "Std. err. alpha_hat= 1.779216144204821e-05\n",
      "Std. err. mu_hat= 0.0028941600428499404\n",
      "Std. err. sig_hat= 0.0006416940382451474\n",
      "Std. err. p_hat= 0.0019657697891615374\n"
     ]
    }
   ],
   "source": [
    "d_err2 = Jac_err(datavals, unif_vals, alpha_SMM2, mu_SMM2, sig_SMM2, p_SMM2, False)\n",
    "print(d_err2)\n",
    "SigHat2 = (1 / S) * lin.inv(d_err2.T @ W_hat2 @ d_err2)\n",
    "print(SigHat2)\n",
    "print('Std. err. alpha_hat=', np.sqrt(SigHat2[0, 0]))\n",
    "print('Std. err. mu_hat=', np.sqrt(SigHat2[1, 1]))\n",
    "print('Std. err. sig_hat=', np.sqrt(SigHat2[2, 2]))\n",
    "print('Std. err. p_hat=', np.sqrt(SigHat2[3, 3]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
